{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Exposición**"
      ],
      "metadata": {
        "id": "g91MXNfbOkES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Base Diabetes"
      ],
      "metadata": {
        "id": "rELF5G5_fJKj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ***Integrantes:***\n",
        "\n",
        "*   Valentina Cañon Cañon\n",
        "* Juan Pablo Abril Serna\n",
        "* Sebastian Galvis\n",
        "\n"
      ],
      "metadata": {
        "id": "4QPWaJ4mOkXZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6zHl-__Oh8B"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrD2wLFI4-qU",
        "outputId": "1029f5bc-aa67-4f6c-8eb4-72a3a4554048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/MachineLearning/expo/datos/diabetes.xlsx'"
      ],
      "metadata": {
        "id": "hbMAW6BV5AVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_diabetes = pd.read_excel(file_path)"
      ],
      "metadata": {
        "id": "l1ym5pbq8NrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Limpieza***"
      ],
      "metadata": {
        "id": "5G4DYeAi8eYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_diabetes = df_diabetes.drop_duplicates()"
      ],
      "metadata": {
        "id": "pFCK_uRf8gcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rellenar los valores 0 que no tienen sentido en algunas columnas con la mediana\n",
        "cols = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
        "\n",
        "for col in cols:\n",
        "    median_value = df_diabetes[col].median()\n",
        "    df_diabetes[col] = df_diabetes[col].replace(0, median_value)\n"
      ],
      "metadata": {
        "id": "JI00EQ1K8rBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para eliminar outliers usando IQR\n",
        "def remove_outliers(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "\n",
        "# Aplicar la eliminación de outliers en las columnas numéricas\n",
        "numeric_columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
        "\n",
        "for col in numeric_columns:\n",
        "    df_diabetes = remove_outliers(df_diabetes, col)\n"
      ],
      "metadata": {
        "id": "3ml9GEJp822N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Tamaño del dataset después de la limpieza: {df_diabetes.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7ZE0KvT842l",
        "outputId": "692994d2-7a64-4ed0-fa73-d4070424a94c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del dataset después de la limpieza: (503, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**División de los datos para entrenamiento y test**"
      ],
      "metadata": {
        "id": "cmko3h2N87aF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separar las características y la variable objetivo\n",
        "X = df_diabetes.drop('Outcome', axis=1)\n",
        "y = df_diabetes['Outcome']\n",
        "\n",
        "# Dividir los datos en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "tDn12-dI8_pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Árbol de Decisión***"
      ],
      "metadata": {
        "id": "BlSg0loc9ryg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Árbol de Decisión\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Predicción y evaluación\n",
        "y_pred_tree = decision_tree.predict(X_test)\n",
        "print(f'Exactitud del Árbol de Decisión: {accuracy_score(y_test, y_pred_tree):.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj1RutUs9rTY",
        "outputId": "283a8669-a6cf-44ce-e8b2-b7f07b49f5da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exactitud del Árbol de Decisión: 0.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementación de Bagging (Random Forest)"
      ],
      "metadata": {
        "id": "iQyh74GgRHMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bagging (Bootstrap Aggregating) crea múltiples modelos de la misma clase (por ejemplo, árboles de decisión) y combina sus predicciones promediando o votando"
      ],
      "metadata": {
        "id": "nHAJcz0uRI8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bagging con Random Forest\n",
        "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "random_forest.fit(X_train, y_train)\n",
        "\n",
        "# Predicción y evaluación\n",
        "y_pred_rf = random_forest.predict(X_test)\n",
        "print(f'Exactitud de Random Forest (Bagging): {accuracy_score(y_test, y_pred_rf):.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDR0s_jiRCFY",
        "outputId": "a6942277-178e-4c20-b27c-a36083c8bac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exactitud de Random Forest (Bagging): 0.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Se observa una mejora en la precisión ya que cada árbol corrige errores locales.\n"
      ],
      "metadata": {
        "id": "Wr_OEZtpRz3E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:**\n",
        "Bootstrapping es una técnica estadística que consiste en generar múltiples subconjuntos de datos a partir de un conjunto de datos original utilizando muestreo aleatorio con reemplazo\n",
        "A partir de cada subconjunto (bootstrap sample), se calcula la estadística de interés (por ejemplo, la media, la varianza, etc.)."
      ],
      "metadata": {
        "id": "NSctarob_Z9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementación de Boosting (AdaBoost y Gradient Boosting)"
      ],
      "metadata": {
        "id": "tcJUo7kkRPIg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boosting crea modelos secuenciales donde cada nuevo modelo corrige los errores del anterior."
      ],
      "metadata": {
        "id": "Dy0zBtmfRRuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AdaBoost\n",
        "ada_boost = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=100, random_state=42)\n",
        "ada_boost.fit(X_train, y_train)\n",
        "\n",
        "# Predicción y evaluación\n",
        "y_pred_ada = ada_boost.predict(X_test)\n",
        "print(f'Exactitud de AdaBoost: {accuracy_score(y_test, y_pred_ada):.2f}')\n",
        "\n",
        "# Gradient Boosting\n",
        "gradient_boost = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "gradient_boost.fit(X_train, y_train)\n",
        "\n",
        "# Predicción y evaluación\n",
        "y_pred_gb = gradient_boost.predict(X_test)\n",
        "print(f'Exactitud de Gradient Boosting: {accuracy_score(y_test, y_pred_gb):.2f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNZ6s1UFRMDh",
        "outputId": "7376547b-1544-4bf4-e83b-5b6f55bf74a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exactitud de AdaBoost: 0.76\n",
            "Exactitud de Gradient Boosting: 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estos modelos entrenan secuencialmente, donde cada modelo siguiente se enfoca en los errores del modelo anterior, lo que permite una mejora en casos más difíciles de clasificar."
      ],
      "metadata": {
        "id": "IwvVfRNARxvs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementación de Stacking"
      ],
      "metadata": {
        "id": "9h-mxXrdRXNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stacking combina diferentes modelos (no necesariamente del mismo tipo) y utiliza un modelo meta para hacer la predicción final."
      ],
      "metadata": {
        "id": "1dmsZcuXRZQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelos base para Stacking\n",
        "estimators = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
        "    ('gb', GradientBoostingClassifier(n_estimators=50, random_state=42)),\n",
        "]\n",
        "\n",
        "# Modelo meta\n",
        "stacking = StackingClassifier(estimators=estimators, final_estimator=DecisionTreeClassifier(max_depth=3))\n",
        "stacking.fit(X_train, y_train)\n",
        "\n",
        "# Predicción y evaluación\n",
        "y_pred_stack = stacking.predict(X_test)\n",
        "print(f'Exactitud de Stacking: {accuracy_score(y_test, y_pred_stack):.2f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX4S7g5IRV0a",
        "outputId": "ea5ae645-1143-49f1-df8b-f41f4602d52a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exactitud de Stacking: 0.78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combina diferentes modelos (Random Forest y Gradient Boosting en este caso) y utiliza un clasificador de nivel superior (árbol de decisión) para mejorar la predicción."
      ],
      "metadata": {
        "id": "rEBBcYkMRvbU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparación de resultados"
      ],
      "metadata": {
        "id": "I0YYnN0ZRcoi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparación de un solo arbol de desición a Bagging**"
      ],
      "metadata": {
        "id": "zs8faon9948w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exactitud del Bagging (Random Forest) ya calculado\n",
        "print(f'Exactitud de Random Forest (Bagging): {accuracy_score(y_test, y_pred_rf):.2f}')\n",
        "\n",
        "# Comparación de resultados\n",
        "print(\"Comparación de exactitud:\")\n",
        "print(f'Árbol de Decisión: {accuracy_score(y_test, y_pred_tree):.2f}')\n",
        "print(f'Random Forest (Bagging): {accuracy_score(y_test, y_pred_rf):.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHuKNox3-AgA",
        "outputId": "89c170e3-5b54-4ac4-e531-aefd84c2bb04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exactitud de Random Forest (Bagging): 0.79\n",
            "Comparación de exactitud:\n",
            "Árbol de Decisión: 0.76\n",
            "Random Forest (Bagging): 0.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusines"
      ],
      "metadata": {
        "id": "2IzkkSIc-Bo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Comparación de exactitud de diferentes técnicas:\")\n",
        "print(f'Random Forest (Bagging): {accuracy_score(y_test, y_pred_rf):.2f}')\n",
        "print(f'AdaBoost: {accuracy_score(y_test, y_pred_ada):.2f}')\n",
        "print(f'Gradient Boosting: {accuracy_score(y_test, y_pred_gb):.2f}')\n",
        "print(f'Stacking: {accuracy_score(y_test, y_pred_stack):.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qgR0nAwReZK",
        "outputId": "d51e5929-4b76-43e9-8c67-7cd5eb81999b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparación de exactitud de diferentes técnicas:\n",
            "Random Forest (Bagging): 0.79\n",
            "AdaBoost: 0.76\n",
            "Gradient Boosting: 0.81\n",
            "Stacking: 0.78\n"
          ]
        }
      ]
    }
  ]
}